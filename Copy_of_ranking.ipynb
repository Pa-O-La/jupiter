{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Copy of ranking.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pa-O-La/jupiter/blob/master/Copy_of_ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jKIgHIhU_JX",
        "colab_type": "text"
      },
      "source": [
        "# Week 5: Final Project on University Ranking\n",
        "\n",
        "\n",
        "For this notebook, I used the university ranking dataset from the [KAGGLE] site (https://www.kaggle.com/mylesoneill/world-university-rankings#cwurData.csv).\n",
        "\n",
        "![University](https://github.com/Pa-O-La/jupiter/blob/master/rank_df_img.PNG?raw=1)\n",
        "\n",
        "They started from the question: \n",
        "*Of all the universities in the world, which are the best?*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Ranking universities is a difficult, political, and controversial practice. There are hundreds of different national and international university ranking systems, many of which disagree with each other. This dataset contains three global university rankings from very different places.\n",
        "\n",
        "## University Ranking Data\n",
        "The Times Higher Education World University Ranking is widely regarded as one of the most influential and widely observed university measures. Founded in the United Kingdom in 2010, it has been criticized for its commercialization and for undermining non-English-instructing institutions.\n",
        "\n",
        "The Academic Ranking of World Universities, also known as the Shanghai Ranking, is an equally influential ranking. It was founded in China in 2003 and has been criticized for focusing on raw research power and for undermining humanities and quality of instruction.\n",
        "\n",
        "The Center for World University Rankings, is a less well know listing that comes from Saudi Arabia, it was founded in 2012.\n",
        "\n",
        "How do these rankings compare to each other?\n",
        "Are the various criticisms levied against these rankings fair or not?\n",
        "How does your alma mater fare against the world?\n",
        "\n",
        "\n",
        "## Qs Shanga i University Ranking Data\n",
        "Source: https://en.wikipedia.org/wiki/College_and_university_rankings "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZNN_WPyU_JZ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 1: the Dataset\n",
        "\n",
        "The purpose of this dataset is to predict the age of an abalone through physical characteristics, determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task. Good thing it's already been done for us!\n",
        "\n",
        "Below is the dataset description from the UCI Machine Learning Repository. \n",
        "\n",
        "|Name\t|\tData Type|\tMeasure\t|Description|\n",
        "|\t----\t|\t---------|\t-----\t|-----------|\n",
        "|\tSex\t\t|nominal\t\t|\t|M, F, and I (infant)|\n",
        "|\tLength\t|\tcontinuous\t|mm|\tLongest shell measurement|\n",
        "|\tDiameter\t|continuous|\tmm\t|perpendicular to length|\n",
        "|\tHeight\t|\tcontinuous\t|mm\t|with meat in shell|\n",
        "|\tWhole weight|\tcontinuous\t|grams\t|whole abalone|\n",
        "|\tShucked weight\t|continuous|\tgrams\t|weight of meat|\n",
        "|\tViscera weight\t|continuous|\tgrams\t|gut weight (after bleeding)|\n",
        "|\tShell weight\t|continuous|\tgrams\t|after being dried|\n",
        "|\tRings\t|\tinteger\t\t|\t|+1.5 gives the age in years|\n",
        "\n",
        "Run the cells below to examine the dataset. \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci1Ogyxggkw2",
        "colab_type": "code",
        "outputId": "8c1ef2e3-4bd4-4638-b39a-521ec2c2194c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# Load dataset \n",
        "import csv\n",
        "url = \"https://raw.githubusercontent.com/Pa-O-La/jupiter/master/timesData.csv\"\n",
        "fp = open(url)\n",
        "timesData = csv.reader(fp, delimiter=',')\n",
        "\n",
        "header = next(timesData)\n",
        "first = next(timesData)\n",
        "\n",
        "print(header)\n",
        "print(first)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-29f898b42b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/Pa-O-La/jupiter/master/timesData.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtimesData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://raw.githubusercontent.com/Pa-O-La/jupiter/master/timesData.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ciH1CIF9U_Ja",
        "colab_type": "code",
        "outputId": "80aec231-4a7f-4afa-fa29-cfce39dd9351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# Load Abalone dataset\n",
        "# Remember to change the file location if needed\n",
        "import csv\n",
        "f = open(\"./abalone.csv\")\n",
        "all_lines = csv.reader(f, delimiter = ',')\n",
        "\n",
        "# We define a header ourselves since the dataset contains only the raw numbers.\n",
        "dataset = []\n",
        "header = ['Sex', 'Length', 'Diameter', 'Height', 'Whole Weight', 'Shucked Weight', 'Viscera Weight', \n",
        "          'Shell Weight', 'Rings']\n",
        "for line in all_lines:\n",
        "    d = dict(zip(header, line))\n",
        "    d['Length'] = float(d['Length'])\n",
        "    d['Diameter'] = float(d['Diameter'])\n",
        "    d['Height'] = float(d['Height'])\n",
        "    d['Whole Weight'] = float(d['Whole Weight'])\n",
        "    d['Shucked Weight'] = float(d['Shucked Weight'])\n",
        "    d['Viscera Weight'] = float(d['Viscera Weight'])\n",
        "    d['Shell Weight'] = float(d['Shell Weight'])\n",
        "    d['Rings'] = int(d['Rings'])\n",
        "    dataset.append(d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f34bf7da72fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./abalone.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mall_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# We define a header ourselves since the dataset contains only the raw numbers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './abalone.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iQqFpBqXU_Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See first line of dataset\n",
        "dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni0DAZNhU_Jm",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Simple Statistics\n",
        "\n",
        "This dataset is already cleaned for us and relatively straightforward, without strings or time data. In your final project, you will have to take care of missing or tricky values yourself. \n",
        "\n",
        "Fill in the following cells with the requested information about the dataset. The answers are given so you can check the output of your own code. For floating numbers, don't worry too much about the exact numbers as long as they are quite close -- different systems may have different rounding protocols. \n",
        "\n",
        "Feel free to `import numpy` if you want more practice with it, or just use Python's native structures to play around with the numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DyBHxTLtU_Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q: What is th total number of entries in the dataset?\n",
        "# A: 4177\n",
        "len(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nPz7vOnvU_Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q: What is the average length of an abalone?\n",
        "# A: 0.5239920995930099 or 0.524\n",
        "import numpy\n",
        "len_avg = numpy.mean([d['Length'] for d in dataset])\n",
        "len_avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oQLfYMuaU_Jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q: What is the widest abalone in the dataset (diameter)?\n",
        "# A: 0.65\n",
        "numpy.max([d['Diameter'] for d in dataset])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mHWMPMtrU_J2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q: What is the average number of rings of smaller abalones compared to that of larger abalones? That \n",
        "#    is, do smaller abalones tend to be younger or older than larger abalones? \n",
        "#    We will count small abalones as abalones with lengths less than or equal to the average length of \n",
        "#    an abalone. The average length of an abalone is 0.524. \n",
        "# A: Small Abalones have on average 8.315645514223196 rings.\n",
        "#    Large Abalones have on average 11.192848020434228 rings.\n",
        "ageSmall = numpy.mean([d['Rings'] for d in dataset if d['Length'] <= len_avg])\n",
        "ageLarge = numpy.mean([d['Rings'] for d in dataset if d['Length'] > len_avg])\n",
        "# Change variable name if necessary\n",
        "print('Small Abalones have on average', ageSmall, 'rings.')\n",
        "print('Large Abalones have on average', ageLarge, 'rings.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8idSfuRU_J8",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Data Visualizations\n",
        "\n",
        "In this course, we learned about [Matplotlib](https://matplotlib.org), a \"Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms\". There are a [variety of plots and figures](https://matplotlib.org/gallery/index.html) we can make with Matplotlib, and in conjunction with NumPy, becomes a powerful and versatile tool in your skillset.\n",
        "\n",
        "In lectures, we covered the basics of line plots, histograms, scatter plots, bar plots, and box plots. Let's try out a few below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "diBqyIWQU_J9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "import numpy\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er8Nx2VBU_KE",
        "colab_type": "text"
      },
      "source": [
        "### Line Plots\n",
        "\n",
        "Line plots show the change in data over time. The example Line Plot below plots the change in density as abalones age (i.e. the distribution of rings). **Note that a line plot is not necessarily the best way to show this data since it doesn't deal with a trend!** Use a histogram (next step) to better showcase this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tNGun8BwU_KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parse out Rings column from dataset\n",
        "rings = [d['Rings'] for d in dataset]\n",
        "rings.sort()\n",
        "\n",
        "# Count number of abalones with each number of rings with defaultdict\n",
        "abalone_rings = defaultdict(int)\n",
        "for r in rings:\n",
        "    abalone_rings[r] += 1\n",
        "X = list(abalone_rings.keys())\n",
        "Y = list(abalone_rings.values())\n",
        "\n",
        "# Customize plot\n",
        "plt.gca().set(xlabel='Rings', ylabel='Number of Abalones',\n",
        "       title='Abalone Age Distribution')\n",
        "plt.grid()\n",
        "\n",
        "# Show the plot of Rings vs Number of Abalones\n",
        "plt.plot(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu5VZNZgU_KL",
        "colab_type": "text"
      },
      "source": [
        "### Histograms\n",
        "\n",
        "Histograms show the distribution of numeric continuous variables with central tendency and skewness. **Using the line plot data from above, plot a histogram showing the distribution of abalone age.** Feel free to explore [matplotlib](https://matplotlib.org/gallery/index.html) on your own to customize your histogram and the following visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SFAunlhzU_KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Complete this cell with a histogram of abalone age distribution\n",
        "\n",
        "# Flatten distribution list into frequency distribution\n",
        "age_freq = []\n",
        "for key in abalone_rings.keys():\n",
        "    for i in range(0, abalone_rings.get(key)):\n",
        "        age_freq.append(key)\n",
        "print(age_freq[:10])\n",
        "\n",
        "# Customize plot\n",
        "plt.gca().set(xlabel='Rings', ylabel='Number of Abalones',\n",
        "       title='Abalone Rings Frequency')\n",
        "plt.grid()\n",
        "\n",
        "# Plot your histogram here\n",
        "plt.hist(age_freq, histtype='bar', rwidth = 0.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOBVauFLU_KS",
        "colab_type": "text"
      },
      "source": [
        "### Scatter Plots\n",
        "\n",
        "Scatter plots show the strength of a relationship between two variables (also known as correlations). From *Part 2: Simple Statistics*, we see that larger abalones tend to be larger, at least from a numbers perspective. **Let's see if this is actually true by creating a scatter plot showing the relationship between `Rings` and `Length`.** \n",
        "\n",
        "*On Your Own:* Read up on `sciPy` and how you can calculate and graph the correlation as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4822hDRUU_KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Complete this cell with a scatter plot of age vs length\n",
        "rings = [d['Rings'] for d in dataset]\n",
        "length = [d['Length'] for d in dataset]\n",
        "\n",
        "# Customize plot\n",
        "plt.gca().set(xlabel='Rings', ylabel='Length',\n",
        "       title='Abalone Rings number on length')\n",
        "plt.grid()\n",
        "\n",
        "# Plot your histogram here\n",
        "plt.scatter(rings,length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8XOkk43U_KY",
        "colab_type": "text"
      },
      "source": [
        "### Bar Plots\n",
        "\n",
        "Bar plots are great for comparing categorical variables. There are a few subtypes of bar plots, such as the grouped bar chart or stacked bar chart. Since we have the `Sex` field to play with, we can compare data across `M` and `F` abalones. Below is a simple stacked bar chart comparing the `Sex` category with the `Shucked Weight` data. **Create a bar chart of your choice of data.** \n",
        "\n",
        "You may refer to the cell below to parse out fields by sex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eaHdoXQqU_KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example Stacked Bar Chart - Comparisons Between Sexes\n",
        "Mweight = sum([d['Shucked Weight'] for d in dataset if d['Sex'] is 'M'])\n",
        "Fweight = sum([d['Shucked Weight'] for d in dataset if d['Sex'] is 'F'])\n",
        "index = [1]\n",
        "\n",
        "p1 = plt.bar(index, Mweight, color='lightblue')\n",
        "p2 = plt.bar(index, Fweight, bottom=Mweight, color='pink')\n",
        "plt.gca().set(title='Abalone Shucked Weight by Sex', ylabel='Total Shucked Weight (g)');\n",
        "plt.xticks([])\n",
        "\n",
        "plt.legend((p1[0], p2[0]), ('Male', 'Female'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8KXbm86UU_Kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Complete this cell with your choice of data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY-d46nTU_Kg",
        "colab_type": "text"
      },
      "source": [
        "### Box Plots\n",
        "\n",
        "Box plots are useful for comparing distributions of data and are commonly found in research papers. The box portion of a box plot represents 50% of the data, and there are versions where you can mark outliers and other extremes. We have the distribution of rings already from the line plot example under the variable name `age_freq`, assuming you haven't modified it. **Find the distribution of another field of your choice and create one or more box plots with both of these fields.**\n",
        "\n",
        "*Hint: You can plot multiple box plots with the command `plt.boxplot([plot1, plot2, ..., plotn])` or use `subplots()` to draw multiple separate plots at the same time. See [this matplotlib example](https://matplotlib.org/gallery/statistics/boxplot_demo.html#sphx-glr-gallery-statistics-boxplot-demo-py) for more.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MzWlZX4mU_Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Complete this cell with multiple box plots\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwPL5lkSU_Kn",
        "colab_type": "text"
      },
      "source": [
        "### Free Response (optional)\n",
        "\n",
        "Experiment and create visualizations of your own here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LJ0ANqc4U_Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Description of visualization\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESbJkYWbU_Ks",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Web Scraping (Optional)\n",
        "\n",
        "**BeautifulSoup Documentation:** https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "\n",
        "This part of the notebook is not graded, but still contains some valuable tips for web-scraping! You were introduced to a method of creating your own dataset by parsing a webpage in lecture videos and this week's notebook. Here is another way to parse a webpage with BeautifulSoup. We will be using a short story from Project Gutenberg [(*Little Boy*](http://www.gutenberg.org/files/58743/58743-h/58743-h.htm)  by Harry Neal, 1954) as an example.\n",
        "\n",
        "*On Your Own:* Read this page on webscraping and try out a project! https://automatetheboringstuff.com/chapter11/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shknEsHsU_Kt",
        "colab_type": "text"
      },
      "source": [
        "### Introduction to Beautiful Soup\n",
        "\n",
        "Below are a few useful commands we will be using throughout the next section as we parse a webpage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "URgd5aKNU_Kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mionYtdLU_Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open and extract HTML from the webpage\n",
        "f = urlopen(\"http://www.gutenberg.org/files/58743/58743-h/58743-h.htm\")\n",
        "html = str(f.read())\n",
        "\n",
        "# First 100 characters of the HTML we grabbed\n",
        "html[:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-Q_WQ_hUU_K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert our HTML object to a BeautifulSoup object and make it readable\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "print(soup.prettify())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urAy9k51U_K6",
        "colab_type": "text"
      },
      "source": [
        "With a BeautifulSoup object, we can easily search through HTML and create lists and other structures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r84HO4tmU_K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of paragraph tags\n",
        "len(soup.find_all('p'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7Z0hg8XWU_K9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create list of all paragraphs\n",
        "paragraph_list = soup.find_all('p')\n",
        "paragraph_list[100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPUvMnVbU_LA",
        "colab_type": "text"
      },
      "source": [
        "We can also extract all the text from a page and use it to create a bag of words or other measures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-TMSQ5evU_LB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract all text from page\n",
        "text = soup.get_text()\n",
        "text[:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "liLLEND_U_LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "from collections import defaultdict\n",
        "\n",
        "letters = defaultdict(int)\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "for char in text:\n",
        "    if char not in punctuation:\n",
        "        letters[char] += 1\n",
        "    \n",
        "letters.items()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKBa31jQU_LJ",
        "colab_type": "text"
      },
      "source": [
        "### Creating Our Own Dataset\n",
        "\n",
        "![Cooking](https://github.com/Pa-O-La/jupiter/blob/master/chef.jpg?raw=1)\n",
        "\n",
        "In previous lectures and notebooks, we wrote our own parser method to extract parts of the text. Here is a trivial example of how you can do the same with BeautifulSoup using a list of [Top 10 Chefs by Gazette Review](https://gazettereview.com/2017/04/top-10-chefs/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BKhWLXmZU_LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open and extract HTML from the webpage\n",
        "f = urlopen(\"https://gazettereview.com/2017/04/top-10-chefs/\")\n",
        "html = str(f.read())\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "print(soup.prettify())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWV2mPyiU_LP",
        "colab_type": "text"
      },
      "source": [
        "Note that all the names of the chefs are between `<h2>` and `</h2>` tags and the descriptions are between `<p>` and `</p>` tags. We can get the names of the chefs quite easily, as seen below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "38vFY5ZVU_LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of chef names\n",
        "# Note that find_all() returns a bs4 object, rather than a Python list.\n",
        "# The HTML tags are also part of the object.\n",
        "chefs = soup.find_all('h2')\n",
        "print(type(chefs))\n",
        "print(chefs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LAi21PfxU_LV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean and strip spaces and numbers from the bs4 element and turn it into a Python list\n",
        "import string\n",
        "letters = set(string.ascii_letters)\n",
        "chef_name = []\n",
        "\n",
        "# Grab relevant letters/spaces and remove extra HTML tags and spaces\n",
        "for chef in chefs:\n",
        "    chef = [letter for letter in str(chef) if letter in letters or letter is ' ']\n",
        "    chef = ''.join(chef[2:len(chef) - 1])\n",
        "    chef_name.append(chef)\n",
        "\n",
        "chef_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rudQ9E7sU_La",
        "colab_type": "text"
      },
      "source": [
        "Getting the list of chef names is trivial with the `find_all()` function (and a little Python cleaning), but what about the descriptions? This is a little trickier since there may be overlapping uses for the `<p>` and `</p>` tags, so let's try [navigating the BeautifulSoup tree](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-the-tree).\n",
        "\n",
        "This website is simple in that every chef has a two-paragraph description in the same format. We can use this to our advantage once we know what to look for. Let's say we want to extract just the text from these two paragraphs. How can we do so? With the `.contents` attribute, we can access the children of each tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xhuZoN47U_La",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptions = soup.find_all('p')\n",
        "del descriptions[-12:]\n",
        "del descriptions[0]\n",
        "print(\"The number of paragraphs is:\", len(descriptions))\n",
        "descriptions[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IpgnDSHbU_Le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the loop\n",
        "i = 0\n",
        "chef_description = [''] * 10\n",
        "chef_image = []\n",
        "\n",
        "# Grab description text from paragraphs\n",
        "for d in descriptions:\n",
        "    curr_desc = []\n",
        "    if i % 2 == 0:\n",
        "        curr_desc = d.contents[2]\n",
        "        chef_image.append(d.contents[0]['src']) # Get images as well\n",
        "    else:\n",
        "        curr_desc = d.contents[0]\n",
        "    # Append relevant parts to corresponding index\n",
        "    chef_description[int(i / 2)] = chef_description[int(i / 2)] + ' ' + curr_desc\n",
        "    i += 1\n",
        "\n",
        "# Voila! We have combined 2 paragraphs into 1.\n",
        "chef_description[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8uFDzJ2U_Lh",
        "colab_type": "text"
      },
      "source": [
        "We now have lists with the names, descriptions, and images of the chefs! You can arrange this however you want; `chef_data` below is arranged like a JSON object but you can modify this section to make the data look more like a traditional dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s3_jvhPGU_Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chef_data = {}\n",
        "\n",
        "chef_data['Name'] = chef_name\n",
        "chef_data['Description'] = chef_description\n",
        "chef_data['Image'] = chef_image\n",
        "\n",
        "chef_data['Description'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMu7JTtOU_Lm",
        "colab_type": "text"
      },
      "source": [
        "### (Optional) Your Turn: Web-Scraping\n",
        "\n",
        "Now that you've run through this section of the notebook, feel free to experiment with web-scraping on your own. Choose a site and get some raw data out of it!\n",
        "\n",
        "*Note: If you run into a `HTTP error 403 (Forbidden)`, this means that the site probably blocks web-scraping scripts. You can get around this by modifying the way you request the URL (see [StackOverflow](https://stackoverflow.com/questions/28396036/python-3-4-urllib-request-error-http-403) for some useful tips) or try another site.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5-GszjDJU_Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start parsing here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43A7_ZNRU_Lp",
        "colab_type": "text"
      },
      "source": [
        "## All Done!\n",
        "\n",
        "In this notebook, we covered loading a dataset, simple statistics, basic data visualizations, and web-scraping to round out your toolset. These will be immensely helpful as you move forwards in building your skills in data science.\n",
        "\n",
        "By now, you hopefully feel a little more confident with tackling your final project. It is up to you to find your own data, build your own notebook, and show others what you have achieved. Best of luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oZb48afkU_Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}